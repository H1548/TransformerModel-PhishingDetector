import json
import torch
import torch.nn as nn
from torch.nn import functional as F
import torch.optim as optim
from tokenizers import Tokenizer
from FineTuningmodel import Transformer
from utils import tokenize_data, pad_sequence, create_mask

device = 'cuda' if torch.cuda.is_available() else 'cpu'
CUDA_LAUNCH_BLOCKING=1

tokenize = Tokenizer.from_file("tokenizer.json")

vocab_size = tokenize.get_vocab_size()
pad_token = tokenize.token_to_id('[PAD]')
unk_token = tokenize.token_to_id('[UNK]')
mask_token = tokenize.token_to_id('[MASK]')
bos_token  = tokenize.token_to_id("[BOS]")
eos_token = tokenize.token_to_id("[EOS]")
mask_spread = 0.15
num_layers = 10


AI_DISCLAIMER = "Note: This recommendation was generated by an AI system. Please follow the company's security policy if unsure."

with open("Advice.json","r") as f:
    Response_map = json.load(f)

def generate_response(label): 
    if label in Response_map:
        response_data = Response_map[label]
    else: 
        response_data = {
            "recommended_action" : "Proceed with caution. Unable to classify email type.", 
            "user_advice": "Avoid clicking any links or replying to the sender. Contact your IT team if unsure."
        }
    
    return (f'{label}: Recommended Action: {response_data["recommended_action"]} User Advice: {response_data["user_advice"]}\nAi Disclaimer: {AI_DISCLAIMER}')
# { 
#         "label": label,
#         "recommended_action": response_data["recommended_action"],
#         "user_advice": response_data["user_advice"],
#         "ai_disclaimer": AI_DISCLAIMER
#     }

model = Transformer(num_layers)
m = model.to(device)

checkpoint = torch.load('MultiFineBest/BestModel.tar')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()


prompt = input('Enter Your Email: ')
output = model.prompt(prompt, bos_token, eos_token, pad_sequence, pad_token,create_mask)


result = generate_response(output)
print(result)
